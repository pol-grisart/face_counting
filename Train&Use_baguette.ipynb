{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stanislas Deneuville - Emmanuel Ferrandi - Pol Grisart - Marine MÃ©dard\n",
    "# Project of data science :  Face recognition in a video and counting\n",
    "16/11/2018\n",
    "\n",
    "## Part II : Train&Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import keras\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum number of faces per image the network will train for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CATEGORY = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__split__ : split the set into two well mixed set \n",
    "\n",
    "\n",
    "In : \n",
    "* data : list of all the images \n",
    "\n",
    "Out : \n",
    "* train_set : list of the images in the training set representing 66% of data\n",
    "* test_set : list of the images in the test set representing the other 34% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TEST_RATIO = 0.66\n",
    "def split(data:list, train_test_ratio:int=TRAIN_TEST_RATIO, random_split=True) :\n",
    "    if random_split:\n",
    "        # Shuffle\n",
    "        random.shuffle(data)\n",
    "    \n",
    "    # Split data\n",
    "    cut_index = round(len(data) * train_test_ratio) \n",
    "    train_set = data[:cut_index]\n",
    "    test_set = data[cut_index:]\n",
    "    return(train_set, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Equalize__: cut data subsets to have the same number of images for each possible output value\n",
    "(Also plot the initial number of sample of each subset) \n",
    "In : \n",
    "* data : list of list of data elements\n",
    "Out : \n",
    "* equalized data sets : list of list of data elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize(subsets):\n",
    "    print(\"Equalizing subset\")\n",
    "    for nb_face,subset in enumerate(subsets):\n",
    "        print(\"{} faces set contains {} images\".format(nb_face, len(subset)))\n",
    "    subsets_length = [len(subset) for subset in subsets]\n",
    "    \n",
    "    # plot subsets length\n",
    "    plt.bar([k for k in range(len(subsets))], subsets_length)\n",
    "    plt.ylabel('number of sample')\n",
    "    plt.xlabel('number of faces in sample')\n",
    "    plt.title('number of sample for each output value')\n",
    "    plt.show()\n",
    "    \n",
    "    minimum = max(100,min(subsets_length))\n",
    "    cutted_subsets = [subset[:minimum] for subset in subsets]\n",
    "    return cutted_subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__load_and_split__ : Load all the available cleaned data, equalize, split and shuffle it\n",
    "\n",
    "\n",
    "In : \n",
    "\n",
    "Out : \n",
    "* train_set : list of the images in the training set representing 66% of data\n",
    "* test_set : list of the images in the test set representing the other 34% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split():\n",
    "    subsets = [[] for k in range(MAX_CATEGORY+1)]\n",
    "    for nb_face in range(MAX_CATEGORY+1):\n",
    "        folder_path = os.path.join(\"train_set\", str(nb_face))\n",
    "        if (os.path.isdir(folder_path)) :\n",
    "\n",
    "            # Y value of these alements\n",
    "            categorical_y = np.zeros((1, MAX_CATEGORY+1))\n",
    "            categorical_y[0, nb_face] = 1\n",
    "\n",
    "            folder_path = os.path.join(\"train_set\", str(nb_face))\n",
    "            for filename in os.listdir(folder_path):\n",
    "                # Filter non image files\n",
    "                if \".jpeg\" in filename or \".png\" in filename or \".jpg\" in filename:\n",
    "                    x = plt.imread(os.path.join(folder_path, filename)).reshape((1, 50,50))\n",
    "                    y = categorical_y\n",
    "                    xy = (x,y)\n",
    "                    subsets[nb_face].append(xy)\n",
    "    \n",
    "    # Equalize to have the same number of each Y value\n",
    "    equalized_subsets = equalize(subsets)\n",
    "    \n",
    "    # Split data respecting equalization\n",
    "    train_set, test_set = [], []\n",
    "    for subset in equalized_subsets:\n",
    "        add_train_set, add_test_set = split(subset)\n",
    "        train_set = train_set + add_train_set\n",
    "        test_set = test_set + add_test_set\n",
    "    \n",
    "    # Shuffle\n",
    "    random.shuffle(train_set)\n",
    "    random.shuffle(test_set)\n",
    "    \n",
    "    print(\"Train size = {}, test size = {}\".format(len(train_set), len(test_set)))\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__AccuracyPlotMemory__: memorise the value of the accuracy all over the training in order to plot it at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyPlotMemory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.plot_y = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.plot_y.append(logs.get('acc'))\n",
    "        \n",
    "    def plot(self):\n",
    "        plt.plot([k+1 for k in range(len(self.plot_y))], self.plot_y)\n",
    "        \n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.show()\n",
    "        \n",
    "plot_callback = AccuracyPlotMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__train_neuural_network__ : function that creates a neural network and trains it with the train_set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    # Simple model\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    # OLD MODEL\n",
    "    #model.add(keras.layers.Dense(units=500, activation='relu', input_dim=50*50))\n",
    "    #model.add(keras.layers.Dense(units=100, activation='relu'))\n",
    "    #model.add(keras.layers.Dense(units=40, activation='relu'))\n",
    "    #model.add(keras.layers.Dense(units=15, activation='relu'))\n",
    "    \n",
    "    \n",
    "    # Convolutionnal layers\n",
    "    model.add(keras.layers.Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=(50,50, 1)))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(keras.layers.Conv2D(64, (5, 5), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    # End with classic layers\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(3000, activation='relu'))\n",
    "    #model.add(keras.layers.Dense(700, activation='relu'))  # Trying adding one or two more layers doesn't provide any amelioration\n",
    "    #model.add(keras.layers.Dense(100, activation='relu'))\n",
    "    model.add(keras.layers.Dense(MAX_CATEGORY+1, activation='softmax'))\n",
    "    \n",
    "    # Define learning process\n",
    "    # loss choices : categorical_crossentropy or categorical_hinge\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "    return model \n",
    "\n",
    "def train_neural_network(train_set, test_set=None):\n",
    "    print(\"Generating model\")\n",
    "    model = generate_model()\n",
    "    \n",
    "    # Convert tain set in a format readable by keras\n",
    "    x_train = np.concatenate([x for x,y in train_set]).reshape(len(train_set), 50, 50, 1)\n",
    "    y_train = np.concatenate([y for x,y in train_set])\n",
    "    print(\"X train size = {}, y train  size = {}\".format(x_train.shape, y_train.shape))\n",
    "    \n",
    "    # If test set is provided for a better evaluation during the training \n",
    "    xy_test = None\n",
    "    if test_set is not None:\n",
    "        # Convert test set in a format readable by keras\n",
    "        x_test = np.concatenate([x for x,y in test_set]).reshape(len(test_set), 50, 50, 1)\n",
    "        y_test = np.concatenate([y for x,y in test_set])\n",
    "        xy_test = x_test, y_test\n",
    "    \n",
    "    print(\"Start training\")\n",
    "    model.fit(x_train, y_train, epochs=30, batch_size=32, callbacks=[plot_callback], validation_data=xy_test)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__evaluate_performance__ : function that applys the neural network on the images in the test_set and compare with the real number of faces in these images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(model, test_set):\n",
    "    # Convert test set in a format readable by keras\n",
    "    x_test = np.concatenate([x for x,y in test_set]).reshape(len(test_set), 50, 50, 1)\n",
    "    y_test = np.concatenate([y for x,y in test_set])\n",
    "    \n",
    "    # Evaluate perfoamance\n",
    "    loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)\n",
    "    \n",
    "    # Display accuracy plot\n",
    "    plot_callback.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute all the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split\n",
      "Train size = 290, test size = 146\n",
      "Train\n",
      "Generating model\n",
      "X train size = (290, 50, 50, 1), y train  size = (290, 31)\n",
      "Start training\n",
      "Epoch 1/30\n",
      "290/290 [==============================] - 3s 10ms/step - loss: 12.7287 - acc: 0.1862\n",
      "Epoch 2/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9855 - acc: 0.1862\n",
      "Epoch 3/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9855 - acc: 0.1862\n",
      "Epoch 4/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9855 - acc: 0.1862\n",
      "Epoch 5/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9855 - acc: 0.1862\n",
      "Epoch 6/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9854 - acc: 0.1862\n",
      "Epoch 7/30\n",
      "290/290 [==============================] - 3s 9ms/step - loss: 12.9854 - acc: 0.1862\n",
      "Epoch 8/30\n",
      "290/290 [==============================] - 3s 9ms/step - loss: 12.9854 - acc: 0.1862\n",
      "Epoch 9/30\n",
      "290/290 [==============================] - 3s 9ms/step - loss: 12.9854 - acc: 0.1862\n",
      "Epoch 10/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9854 - acc: 0.1862\n",
      "Epoch 11/30\n",
      "290/290 [==============================] - 3s 10ms/step - loss: 12.9853 - acc: 0.1862\n",
      "Epoch 12/30\n",
      "290/290 [==============================] - 2s 9ms/step - loss: 12.9853 - acc: 0.1862\n",
      "Epoch 13/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9853 - acc: 0.1862\n",
      "Epoch 14/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9853 - acc: 0.1862\n",
      "Epoch 15/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9852 - acc: 0.1862\n",
      "Epoch 16/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9852 - acc: 0.1862\n",
      "Epoch 17/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9852 - acc: 0.1862\n",
      "Epoch 18/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9852 - acc: 0.1862\n",
      "Epoch 19/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9851 - acc: 0.1862\n",
      "Epoch 20/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9851 - acc: 0.1862\n",
      "Epoch 21/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9851 - acc: 0.1862\n",
      "Epoch 22/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9851 - acc: 0.1862\n",
      "Epoch 23/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9850 - acc: 0.1862\n",
      "Epoch 24/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9850 - acc: 0.1862\n",
      "Epoch 25/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9850 - acc: 0.1862\n",
      "Epoch 26/30\n",
      "290/290 [==============================] - 2s 9ms/step - loss: 12.9850 - acc: 0.1862\n",
      "Epoch 27/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9850 - acc: 0.1862\n",
      "Epoch 28/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9849 - acc: 0.1862\n",
      "Epoch 29/30\n",
      "290/290 [==============================] - 3s 9ms/step - loss: 12.9849 - acc: 0.1862\n",
      "Epoch 30/30\n",
      "290/290 [==============================] - 2s 8ms/step - loss: 12.9849 - acc: 0.1862\n",
      "Save\n",
      "Saved model to disk\n",
      "Evaluate\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size = 1038, test size = 533\n",
      "Train\n",
      "Generating model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
     ]
    }
   ],
   "source": [
    "print(\"Split\")\n",
    "train_set, test_set = load_and_split()\n",
    "\n",
    "print(\"Train\")\n",
    "model = train_neural_network(train_set)\n",
    "\n",
    "print(\"Evaluate\")\n",
    "evaluate_performance(model, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__manual_evaluation__: provide a clear humain overview of the final performance of network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def manual_evaluation(model, test_et):\n",
    "    x_test = np.concatenate([x for x,y in test_set]).reshape(len(test_set), 50, 50, 1)\n",
    "    y_test = np.concatenate([y for x,y in test_set])\n",
    "    outs = model.predict(x_test)\n",
    "    \n",
    "    result = [[] for k in range(MAX_CATEGORY + 1)]\n",
    "    \n",
    "    square_error = 0\n",
    "    perfect_accuracy = 0\n",
    "    count = 0\n",
    "    \n",
    "    for y_out, y_expected in zip(outs, y_test):\n",
    "        #print(\">>\",y_out,\"/expects/\",y_expected)\n",
    "        clean_expected_out = 0\n",
    "        while not y_expected[clean_expected_out] == 1:\n",
    "            clean_expected_out += 1\n",
    "        clean_out = y_out.argmax()\n",
    "        result[clean_expected_out].append(clean_out)\n",
    "        \n",
    "        square_error += abs(clean_expected_out-clean_out)**2\n",
    "        if clean_out == clean_expected_out:\n",
    "            perfect_accuracy += 1\n",
    "        count += 1\n",
    "        \n",
    "    #print(\"==================\")\n",
    "    for k,line in enumerate(result):\n",
    "        print(k,line)\n",
    "    \n",
    "    print(\"Mean square error {}\".format(square_error/count))\n",
    "    print(\"perfect match rate {}%\".format(round(perfect_accuracy/count*100), 2))\n",
    "    return square_error/count, perfect_accuracy/count\n",
    "mean_square_error, perfect_accuracy = manual_evaluation(model, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the network for later reuse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "\n",
    "# JSON\n",
    "json_model = model.to_json()\n",
    "with open(\"model_CNN_{}.json\".format(round(perfect_accuracy*100)), \"w\") as f:\n",
    "    f.write(json_model)\n",
    "# Weights\n",
    "model.save_weights(\"weight_CNN_{}.h5\".format(round(perfect_accuracy*100)))\n",
    "print(\"Model saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
